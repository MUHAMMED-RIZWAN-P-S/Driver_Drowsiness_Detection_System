{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "042f6a93",
   "metadata": {},
   "source": [
    "#### This Module detects drowsiness in a driver by combining computer vision and unsupervised machine learning algorithms to detect and predict if the driver is drowsy or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e12c44",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c585e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9edebe2",
   "metadata": {},
   "source": [
    "Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "489940e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drowsiness detection using face landmark detection\n",
    "mp_sol = mp.solutions\n",
    "mp_drawing = mp_sol.drawing_utils\n",
    "mp_drawing_styles = mp_sol.drawing_styles\n",
    "mp_face_mesh = mp_sol.face_mesh\n",
    "facemesh = mp_face_mesh.FaceMesh(max_num_faces = 1)\n",
    "mp_holistic = mp_sol.holistic\n",
    "\n",
    "landmark_style = mp_drawing.DrawingSpec((0,255,0), thickness=1, circle_radius=1)\n",
    "connection_style = mp_drawing.DrawingSpec((0,0,255), thickness=1, circle_radius=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37c446d",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "980c75d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "FACE = [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, \n",
    "        152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103,67, 109]\n",
    "LIPS = [61, 146, 91, 181, 84, 17, 314, 405, 321, 375,291, 308, 324, 318, 402, 317, 14, 87, 178, \n",
    "        88, 95, 185, 40, 39, 37, 0, 267, 269, 270, 409, 415, 310, 311, 312, 13, 82, 81, 42, 183, 78]\n",
    "LOWER_LIPS = [61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95]\n",
    "UPPER_LIPS = [185, 40, 39, 37, 0, 267, 269, 270, 409, 415, 310, 311, 312, 13, 82, 81, 42, 183, 78] \n",
    "\n",
    "# Left eyes indices \n",
    "LEFT_EYE = [362, 398, 384, 385, 386, 387, 388, 466, 382, 381, 380, 374, 373, 390, 249, 263]\n",
    "LEFT_EYEBROW = [336, 296, 334, 293, 300, 276, 283, 282, 295, 285]\n",
    "\n",
    "# Right eyes indices\n",
    "RIGHT_EYE = [33, 246, 161, 160, 159, 158, 157, 173, 7, 163, 144, 145, 153, 154, 155, 133]  \n",
    "RIGHT_EYEBROW = [70, 63, 105, 66, 107, 55, 65, 52, 53, 46]\n",
    "\n",
    "EYES = [362, 398, 384, 385, 386, 387, 388, 466, 382, 381, 380, 374, 373, 390, 249, 263, \n",
    "        33, 246, 161, 160, 159, 158, 157, 173, 7, 163, 144, 145, 153, 154, 155, 133] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8253e6",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bf6546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eu_dist(pt1,pt2):\n",
    "    x = np.square(pt2[0] - pt1[0])\n",
    "    y = np.square(pt2[1] - pt1[1])\n",
    "    z = np.square(pt2[2] - pt1[2])\n",
    "    dist = np.sqrt(x + y + z)\n",
    "    return(dist)\n",
    "\n",
    "\n",
    "def blinked(le_nll, re_nll):\n",
    "    left_v, right_v, ratio_le, ratio_re = 0, 0, 0, 0\n",
    "    \n",
    "    if len(le_nll) == 0 or len(re_nll) == 0:\n",
    "        l_val, r_val = 0, 0\n",
    "    \n",
    "    else:\n",
    "        # h for horizontal, v for vertical\n",
    "        left_h = eu_dist(le_nll[0], le_nll[15])\n",
    "        right_h = eu_dist(re_nll[0], re_nll[15])\n",
    "        i = 1\n",
    "        while i < 8:\n",
    "            left_v += eu_dist(le_nll[i], le_nll[i + 7])\n",
    "            right_v += eu_dist(re_nll[i], re_nll[i + 7])\n",
    "            i += 1\n",
    "\n",
    "        ratio_le = left_v/(7*left_h)\n",
    "        ratio_re = right_v/(7*right_h)\n",
    "        \n",
    "        if ratio_le > 0.20:    # citation needed in value of EAR\n",
    "            l_val = 1\n",
    "        else:\n",
    "            l_val = 0\n",
    "\n",
    "        if ratio_re > 0.20:\n",
    "            r_val = 1\n",
    "        else:\n",
    "            r_val = 0\n",
    "\n",
    "    return((l_val, r_val))\n",
    "\n",
    "\n",
    "def aplist(le_nll, re_nll):\n",
    "    le, re = [],[]\n",
    "    if len(le_nll) == 0 or len(re_nll) == 0:\n",
    "        le, re = [], []\n",
    "    else:\n",
    "        le.append(le_nll[2])\n",
    "        le.append(le_nll[14])\n",
    "        le.append(le_nll[8])\n",
    "        le.append(le_nll[9])\n",
    "        le.append(le_nll[10])\n",
    "        le.append(le_nll[11])\n",
    "        le.append(le_nll[12])\n",
    "        le.append(le_nll[15])\n",
    "        le.append(le_nll[7])\n",
    "        le.append(le_nll[6])\n",
    "        le.append(le_nll[5])\n",
    "        le.append(le_nll[4])\n",
    "        le.append(le_nll[3])\n",
    "        le.append(le_nll[13])\n",
    "        le.append(le_nll[0])\n",
    "        le.append(le_nll[1])\n",
    "\n",
    "        re.append(re_nll[1])\n",
    "        re.append(re_nll[15])\n",
    "        re.append(re_nll[12])\n",
    "        re.append(re_nll[11])\n",
    "        re.append(re_nll[10])\n",
    "        re.append(re_nll[9])\n",
    "        re.append(re_nll[8])\n",
    "        re.append(re_nll[14])\n",
    "        re.append(re_nll[0])\n",
    "        re.append(re_nll[13])\n",
    "        re.append(re_nll[3])\n",
    "        re.append(re_nll[4])\n",
    "        re.append(re_nll[5])\n",
    "        re.append(re_nll[6])\n",
    "        re.append(re_nll[7])\n",
    "        re.append(re_nll[2])\n",
    "    \n",
    "    return(le, re)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f9e2fc",
   "metadata": {},
   "source": [
    "Driver Facial Expression Monitoring and Driver Pose Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b6a30fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"eo1.mp4\")\n",
    "\n",
    "frame_no, drowsy = 0, 0\n",
    "with mp_holistic.Holistic(min_detection_confidence = 0.5, min_tracking_confidence = 0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        frame_no += 1\n",
    "        success, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        ih, iw, ic = frame.shape\n",
    "        le_nll, re_nll = [], []\n",
    "        \n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "        \n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        frame.flags.writeable = False\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Make detection\n",
    "        results_fm = facemesh.process(frame)\n",
    "        results_hol = holistic.process(frame)\n",
    "        \n",
    "        frame.flags.writeable = True\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if results_fm.multi_face_landmarks:\n",
    "            for flms in results_fm.multi_face_landmarks:\n",
    "                # Eyes and Face Oval\n",
    "                mp_drawing.draw_landmarks(frame, results_hol.face_landmarks, mp_holistic.FACEMESH_CONTOURS, \n",
    "                                          landmark_drawing_spec = None, connection_drawing_spec = mp_drawing_styles\n",
    "                                          .get_default_face_mesh_contours_style())\n",
    "                # Left Hand Landmarks\n",
    "                mp_drawing.draw_landmarks(frame, results_hol.left_hand_landmarks, mp_sol.hands_connections.HAND_CONNECTIONS,\n",
    "                                          mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=1, circle_radius=1),\n",
    "                                          mp_drawing.DrawingSpec(color=(255, 255, 0), thickness=1, circle_radius=1))\n",
    "                # Right Hand Landmarks\n",
    "                mp_drawing.draw_landmarks(frame, results_hol.right_hand_landmarks, mp_sol.hands_connections.HAND_CONNECTIONS,\n",
    "                                          mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=1, circle_radius=1),\n",
    "                                          mp_drawing.DrawingSpec(color=(255, 255, 0), thickness=1, circle_radius=1))\n",
    "                # Pose Landmarks\n",
    "                mp_drawing.draw_landmarks(frame, results_hol.pose_landmarks, mp_sol.pose.POSE_CONNECTIONS,\n",
    "                                          mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=1, circle_radius=1),\n",
    "                                          mp_drawing.DrawingSpec(color=(255, 255, 0), thickness=1, circle_radius=1))\n",
    "                 \n",
    "                \n",
    "                for id, lms in enumerate(flms.landmark):\n",
    "                    if id in LEFT_EYE:\n",
    "                        x, y, z = lms.x*iw, lms.y*ih, lms.z\n",
    "                        le_nll.append((x, y, z))                        \n",
    "                        \n",
    "                    elif id in RIGHT_EYE:\n",
    "                        x, y, z = lms.x*iw, lms.y*ih, lms.z\n",
    "                        re_nll.append((x, y, z))         \n",
    "    \n",
    "    \n",
    "            status, instruct, color = \"\", \"\", (0,0,0)               \n",
    "            a = aplist(le_nll, re_nll)\n",
    "            a = blinked(a[0], a[1])\n",
    "\n",
    "            if a[0] == 1 or a[1] == 1:\n",
    "                status = \"ALERT.\"\n",
    "                color = (48, 255, 48)\n",
    "                drowsy = 0\n",
    "            \n",
    "            else:\n",
    "                drowsy += 1\n",
    "                status = \"BLINKED\"\n",
    "                color = (48, 255, 200)\n",
    "                if drowsy > 10:\n",
    "                    status = \"DROWSY!!!\"\n",
    "                    color = (0,0,255)\n",
    "\n",
    "                    \n",
    "        cv2.putText(frame, str(frame_no), (100,150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (224, 224, 224), 3)\n",
    "        cv2.putText(frame, status, (100,100), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)\n",
    "        cv2.imshow('MediaPipe', frame)\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe6c0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release and destroy all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
